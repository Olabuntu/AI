{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dfac2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "import xgboost as xgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34ea4cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING GDSC DRUG RESPONSE DATA\n",
      "======================================================================\n",
      "column names: ['Sheet 1']\n",
      "Loaded single sheet:  Sheet 1\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING GDSC DRUG RESPONSE DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "df_raw = pd.ExcelFile('GDSC1_fitted_dose_response.xlsx')\n",
    "print(f'column names: {df_raw.sheet_names}')\n",
    "if len(df_raw.sheet_names) == 1:\n",
    "    name = df_raw.sheet_names[0]\n",
    "    df_raw = pd.read_excel(df_raw, sheet_name=f'{df_raw.sheet_names[0]}')\n",
    "    print('Loaded single sheet: ', name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d38a6888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DATASET', 'NLME_RESULT_ID', 'NLME_CURVE_ID', 'COSMIC_ID',\n",
      "       'CELL_LINE_NAME', 'SANGER_MODEL_ID', 'TCGA_DESC', 'DRUG_ID',\n",
      "       'DRUG_NAME', 'PUTATIVE_TARGET', 'PATHWAY_NAME', 'COMPANY_ID',\n",
      "       'WEBRELEASE', 'MIN_CONC', 'MAX_CONC', 'LN_IC50', 'AUC', 'RMSE',\n",
      "       'Z_SCORE'],\n",
      "      dtype='object')\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATASET</th>\n",
       "      <th>NLME_RESULT_ID</th>\n",
       "      <th>NLME_CURVE_ID</th>\n",
       "      <th>COSMIC_ID</th>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th>SANGER_MODEL_ID</th>\n",
       "      <th>TCGA_DESC</th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>DRUG_NAME</th>\n",
       "      <th>PUTATIVE_TARGET</th>\n",
       "      <th>PATHWAY_NAME</th>\n",
       "      <th>COMPANY_ID</th>\n",
       "      <th>WEBRELEASE</th>\n",
       "      <th>MIN_CONC</th>\n",
       "      <th>MAX_CONC</th>\n",
       "      <th>LN_IC50</th>\n",
       "      <th>AUC</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Z_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GDSC1</td>\n",
       "      <td>342</td>\n",
       "      <td>15580432</td>\n",
       "      <td>684057</td>\n",
       "      <td>ES5</td>\n",
       "      <td>SIDM00263</td>\n",
       "      <td>UNCLASSIFIED</td>\n",
       "      <td>1</td>\n",
       "      <td>Erlotinib</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>EGFR signaling</td>\n",
       "      <td>1045</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.966813</td>\n",
       "      <td>0.985678</td>\n",
       "      <td>0.026081</td>\n",
       "      <td>1.299144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GDSC1</td>\n",
       "      <td>342</td>\n",
       "      <td>15580806</td>\n",
       "      <td>684059</td>\n",
       "      <td>ES7</td>\n",
       "      <td>SIDM00269</td>\n",
       "      <td>UNCLASSIFIED</td>\n",
       "      <td>1</td>\n",
       "      <td>Erlotinib</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>EGFR signaling</td>\n",
       "      <td>1045</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.692090</td>\n",
       "      <td>0.972690</td>\n",
       "      <td>0.110059</td>\n",
       "      <td>0.156076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GDSC1</td>\n",
       "      <td>342</td>\n",
       "      <td>15581198</td>\n",
       "      <td>684062</td>\n",
       "      <td>EW-11</td>\n",
       "      <td>SIDM00203</td>\n",
       "      <td>UNCLASSIFIED</td>\n",
       "      <td>1</td>\n",
       "      <td>Erlotinib</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>EGFR signaling</td>\n",
       "      <td>1045</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.477990</td>\n",
       "      <td>0.944459</td>\n",
       "      <td>0.087019</td>\n",
       "      <td>-0.035912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GDSC1</td>\n",
       "      <td>342</td>\n",
       "      <td>15581542</td>\n",
       "      <td>684072</td>\n",
       "      <td>SK-ES-1</td>\n",
       "      <td>SIDM01111</td>\n",
       "      <td>UNCLASSIFIED</td>\n",
       "      <td>1</td>\n",
       "      <td>Erlotinib</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>EGFR signaling</td>\n",
       "      <td>1045</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.033564</td>\n",
       "      <td>0.950758</td>\n",
       "      <td>0.016290</td>\n",
       "      <td>-0.434437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GDSC1</td>\n",
       "      <td>342</td>\n",
       "      <td>15581930</td>\n",
       "      <td>687448</td>\n",
       "      <td>COLO-829</td>\n",
       "      <td>SIDM00909</td>\n",
       "      <td>SKCM</td>\n",
       "      <td>1</td>\n",
       "      <td>Erlotinib</td>\n",
       "      <td>EGFR</td>\n",
       "      <td>EGFR signaling</td>\n",
       "      <td>1045</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.966007</td>\n",
       "      <td>0.954778</td>\n",
       "      <td>0.180255</td>\n",
       "      <td>0.401702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DATASET  NLME_RESULT_ID  NLME_CURVE_ID  COSMIC_ID CELL_LINE_NAME  \\\n",
       "0   GDSC1             342       15580432     684057            ES5   \n",
       "1   GDSC1             342       15580806     684059            ES7   \n",
       "2   GDSC1             342       15581198     684062          EW-11   \n",
       "3   GDSC1             342       15581542     684072        SK-ES-1   \n",
       "4   GDSC1             342       15581930     687448       COLO-829   \n",
       "\n",
       "  SANGER_MODEL_ID     TCGA_DESC  DRUG_ID  DRUG_NAME PUTATIVE_TARGET  \\\n",
       "0       SIDM00263  UNCLASSIFIED        1  Erlotinib            EGFR   \n",
       "1       SIDM00269  UNCLASSIFIED        1  Erlotinib            EGFR   \n",
       "2       SIDM00203  UNCLASSIFIED        1  Erlotinib            EGFR   \n",
       "3       SIDM01111  UNCLASSIFIED        1  Erlotinib            EGFR   \n",
       "4       SIDM00909          SKCM        1  Erlotinib            EGFR   \n",
       "\n",
       "     PATHWAY_NAME  COMPANY_ID WEBRELEASE  MIN_CONC  MAX_CONC   LN_IC50  \\\n",
       "0  EGFR signaling        1045          Y  0.007813       2.0  3.966813   \n",
       "1  EGFR signaling        1045          Y  0.007813       2.0  2.692090   \n",
       "2  EGFR signaling        1045          Y  0.007813       2.0  2.477990   \n",
       "3  EGFR signaling        1045          Y  0.007813       2.0  2.033564   \n",
       "4  EGFR signaling        1045          Y  0.007813       2.0  2.966007   \n",
       "\n",
       "        AUC      RMSE   Z_SCORE  \n",
       "0  0.985678  0.026081  1.299144  \n",
       "1  0.972690  0.110059  0.156076  \n",
       "2  0.944459  0.087019 -0.035912  \n",
       "3  0.950758  0.016290 -0.434437  \n",
       "4  0.954778  0.180255  0.401702  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_raw.columns)\n",
    "print(len(df_raw.columns))\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b308c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CLEANING COLUMN NAMES\n",
      "======================================================================\n",
      "   Mapped: 'DRUG_NAME' ‚Üí 'Drug_Name'\n",
      "   Mapped: 'CELL_LINE_NAME' ‚Üí 'Cell_Line_Name'\n",
      "   Mapped: 'TCGA_DESC' ‚Üí 'TCGA_Class'\n",
      "   Mapped: 'COSMIC_ID' ‚Üí 'Cosmic_ID'\n",
      "   Mapped: 'PATHWAY_NAME' ‚Üí 'Pathway_Name'\n",
      "   Mapped: 'PUTATIVE_TARGET' ‚Üí 'Putative_Target'\n",
      "   Mapped: 'DRUG_ID' ‚Üí 'Drug_ID'\n",
      "   Mapped: 'SANGER_MODEL_ID' ‚Üí 'Sanger_Model_ID'\n",
      "   Mapped: 'MIN_CONC' ‚Üí 'Min_Conc'\n",
      "   Mapped: 'MAX_CONC' ‚Üí 'Max_Conc'\n",
      "   Mapped: 'Z_SCORE' ‚Üí 'Z_Score'\n",
      "\n",
      "‚úÖ Column mapping complete\n",
      "   Available columns after mapping: ['DATASET', 'NLME_RESULT_ID', 'NLME_CURVE_ID', 'Cosmic_ID', 'Cell_Line_Name', 'Sanger_Model_ID', 'TCGA_Class', 'Drug_ID', 'Drug_Name', 'Putative_Target', 'Pathway_Name', 'COMPANY_ID', 'WEBRELEASE', 'Min_Conc', 'Max_Conc', 'LN_IC50', 'AUC', 'RMSE', 'Z_Score']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLEANING COLUMN NAMES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df_raw.columns = df_raw.columns.str.strip()\n",
    "\n",
    "# Standardizing column names to a consistent format makes the rest of the pipeline cleaner\n",
    "column_mapping = {\n",
    "    'DRUG_NAME': 'Drug_Name',\n",
    "    'CELL_LINE_NAME': 'Cell_Line_Name',\n",
    "    'TCGA_DESC': 'TCGA_Class',\n",
    "    'AUC': 'AUC',\n",
    "    'LN_IC50': 'LN_IC50',\n",
    "    'COSMIC_ID': 'Cosmic_ID',\n",
    "    'PATHWAY_NAME': 'Pathway_Name',\n",
    "    'PUTATIVE_TARGET': 'Putative_Target',\n",
    "    'DRUG_ID': 'Drug_ID',\n",
    "    'SANGER_MODEL_ID': 'Sanger_Model_ID',\n",
    "    'MIN_CONC': 'Min_Conc',\n",
    "    'MAX_CONC': 'Max_Conc',\n",
    "    'RMSE': 'RMSE',\n",
    "    'Z_SCORE': 'Z_Score'\n",
    "}\n",
    "\n",
    "# Apply column mapping (only rename if column exists)\n",
    "for old_name, new_name in column_mapping.items():\n",
    "    if old_name in df_raw.columns:\n",
    "        df_raw.rename(columns={old_name: new_name}, inplace=True)\n",
    "        if old_name != new_name:\n",
    "            print(f\"   Mapped: '{old_name}' ‚Üí '{new_name}'\")\n",
    "\n",
    "print(f\"\\n‚úÖ Column mapping complete\")\n",
    "print(f\"   Available columns after mapping: {list(df_raw.columns)}\")\n",
    "print(len(df_raw.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5bb4c4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "len(df_raw['Cosmic_ID'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad782273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " SELECTING RELEVANT COLUMNS\n",
      "======================================================================\n",
      "‚úÖ Available columns for modeling: ['Drug_Name', 'Cell_Line_Name', 'AUC', 'TCGA_Class', 'Pathway_Name', 'Putative_Target', 'LN_IC50']\n",
      "\n",
      "üìã Column Summary:\n",
      "   Total columns in file: 19\n",
      "   Columns selected for modeling: 7\n",
      "   Columns: Drug_Name, Cell_Line_Name, AUC, TCGA_Class, Pathway_Name, Putative_Target, LN_IC50\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" SELECTING RELEVANT COLUMNS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Focusing on features that are biologically meaningful for drug response prediction\n",
    "columns_to_keep = [\n",
    "    'Drug_Name',\n",
    "    'Cell_Line_Name',\n",
    "    'AUC',\n",
    "    'TCGA_Class',\n",
    "    'Pathway_Name',\n",
    "    'Putative_Target',\n",
    "    'LN_IC50'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Keep only columns that exist in the dataset\n",
    "available_cols = [col for col in columns_to_keep if col in df_raw.columns]\n",
    "missing_cols = [col for col in columns_to_keep if col not in df_raw.columns]\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Available columns for modeling: {available_cols}\")\n",
    "if missing_cols:\n",
    "    print(f\"‚ö†Ô∏è  Missing columns (will be skipped): {missing_cols}\")\n",
    "\n",
    "# Create working dataframe with available columns\n",
    "df = df_raw[available_cols].copy()\n",
    "\n",
    "# Display column info\n",
    "print(f\"\\nüìã Column Summary:\")\n",
    "print(f\"   Total columns in file: {len(df_raw.columns)}\")\n",
    "print(f\"   Columns selected for modeling: {len(available_cols)}\")\n",
    "print(f\"   Columns: {', '.join(available_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21a94561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drug_Name             0\n",
       "Cell_Line_Name        0\n",
       "AUC                   0\n",
       "TCGA_Class          580\n",
       "Pathway_Name          0\n",
       "Putative_Target    3652\n",
       "LN_IC50               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae489c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " TARGET VARIABLE SELECTION\n",
      "======================================================================\n",
      "‚úÖ Using 'AUC' as target variable\n",
      "\n",
      "üìä Data cleaning:\n",
      "   Initial rows: 333,161\n",
      "   After removing missing AUC: 333,161 rows\n",
      "   Removed: 0 rows (0.00%)\n",
      "   After numeric conversion: 333,161 rows\n",
      "   ‚ö†Ô∏è  Found 3192 potential outliers (outside 3*IQR)\n",
      "      Range: [0.151, 1.590]\n",
      "\n",
      "‚úÖ Final data shape: 329,969 rows √ó 7 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" TARGET VARIABLE SELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "target_col = 'AUC'\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    print(f\"‚ùå Error: Target column '{target_col}' not found!\")\n",
    "    print(f\"   Available columns: {df.columns.tolist()}\")\n",
    "    if 'LN_IC50' in df.columns:\n",
    "        print(f\"   Using 'LN_IC50' as alternative target\")\n",
    "        target_col = 'LN_IC50'\n",
    "    else:\n",
    "        raise ValueError(\"No suitable target column found!\")\n",
    "\n",
    "print(f\"‚úÖ Using '{target_col}' as target variable\")\n",
    "\n",
    "print(f\"\\nüìä Data cleaning:\")\n",
    "initial_rows = len(df)\n",
    "print(f\"   Initial rows: {initial_rows:,}\")\n",
    "\n",
    "df = df.dropna(subset=[target_col])\n",
    "print(f\"   After removing missing {target_col}: {len(df):,} rows\")\n",
    "print(f\"   Removed: {initial_rows - len(df):,} rows ({(initial_rows - len(df))/initial_rows*100:.2f}%)\")\n",
    "\n",
    "df[target_col] = pd.to_numeric(df[target_col], errors='coerce')\n",
    "df = df.dropna(subset=[target_col])\n",
    "\n",
    "print(f\"   After numeric conversion: {len(df):,} rows\")\n",
    "\n",
    "# Removing extreme outliers that could skew the model\n",
    "Q1 = df[target_col].quantile(0.25)\n",
    "Q3 = df[target_col].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 3 * IQR\n",
    "upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "outliers = ((df[target_col] < lower_bound) | (df[target_col] > upper_bound)).sum()\n",
    "if outliers > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  Found {outliers} potential outliers (outside 3*IQR)\")\n",
    "    print(f\"      Range: [{lower_bound:.3f}, {upper_bound:.3f}]\")\n",
    "    df = df[(df[target_col] >= lower_bound) & (df[target_col] <= upper_bound)]\n",
    "\n",
    "print(f\"\\n‚úÖ Final data shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49417c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA SAMPLING (OPTIONAL)\n",
      "======================================================================\n",
      "üìâ Sampling 20,000 samples from 329,969 total samples\n",
      "   This speeds up training for experimentation\n",
      "   For final model, set USE_FULL_DATA = True\n",
      "   ‚úÖ Sampled dataset: 20,000 rows\n"
     ]
    }
   ],
   "source": [
    "# The GDSC dataset has 333K+ samples. For faster training, you can sample it.\n",
    "# For production, use the full dataset.\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA SAMPLING (OPTIONAL)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "#  Use full dataset (recommended for final model)\n",
    "USE_FULL_DATA = False\n",
    "\n",
    "#  Sample for faster training/experimentation\n",
    "SAMPLE_SIZE = 20000  # Number of samples to use (if sampling)\n",
    "\n",
    "if not USE_FULL_DATA and len(df) > SAMPLE_SIZE:\n",
    "    print(f\"üìâ Sampling {SAMPLE_SIZE:,} samples from {len(df):,} total samples\")\n",
    "    print(f\"   This speeds up training for experimentation\")\n",
    "    print(f\"   For final model, set USE_FULL_DATA = True\")\n",
    "    \n",
    "    # Stratified sampling by drug (to maintain drug diversity)\n",
    "    if 'Drug_Name' in df.columns:\n",
    "        # Sample proportionally from each drug\n",
    "        df_sampled = df.groupby('Drug_Name', group_keys=False).apply(\n",
    "            lambda x: x.sample(min(len(x), int(SAMPLE_SIZE * len(x) / len(df))), random_state=42)\n",
    "        )\n",
    "        # If we need more samples, randomly sample the rest\n",
    "        if len(df_sampled) < SAMPLE_SIZE:\n",
    "            remaining = df[~df.index.isin(df_sampled.index)]\n",
    "            n_needed = SAMPLE_SIZE - len(df_sampled)\n",
    "            df_sampled = pd.concat([df_sampled, remaining.sample(n_needed, random_state=42)])\n",
    "        df = df_sampled.sample(n=min(SAMPLE_SIZE, len(df_sampled)), random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        df = df.sample(n=SAMPLE_SIZE, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"   ‚úÖ Sampled dataset: {len(df):,} rows\")\n",
    "else:\n",
    "    print(f\"‚úÖ Using full dataset: {len(df):,} rows\")\n",
    "    print(f\"   Note: Training may take longer with full dataset\")\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa42877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPLORATORY DATA ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üìä Dataset Overview:\n",
      "   Total samples: 20,000\n",
      "   Total features: 7\n",
      "\n",
      "üéØ Target Variable (AUC) Statistics:\n",
      "count    20000.000000\n",
      "mean         0.842951\n",
      "std          0.179049\n",
      "min          0.151531\n",
      "25%          0.776113\n",
      "50%          0.919074\n",
      "75%          0.974072\n",
      "max          0.999530\n",
      "Name: AUC, dtype: float64\n",
      "\n",
      "üìã Categorical Features:\n",
      "   Drugs: 378 unique\n",
      "   Top 10 drugs by frequency:\n",
      "Drug_Name\n",
      "Cisplatin             113\n",
      "Olaparib              111\n",
      "JQ1                   111\n",
      "AKT inhibitor VIII    111\n",
      "Avagacestat           111\n",
      "PLX-4720              111\n",
      "AZD6482               110\n",
      "AZD7762               110\n",
      "SB505124              110\n",
      "Afatinib              110\n",
      "\n",
      "   Cell Lines: 958 unique\n",
      "   TCGA Classes: 31 unique\n",
      "   Top 10 TCGA classes:\n",
      "TCGA_Class\n",
      "UNCLASSIFIED    3977\n",
      "LUAD            1585\n",
      "SCLC            1088\n",
      "COREAD          1087\n",
      "SKCM            1074\n",
      "BRCA            1028\n",
      "NB               822\n",
      "DLBC             744\n",
      "HNSC             742\n",
      "GBM              655\n",
      "\n",
      "‚ö†Ô∏è  Missing Values:\n",
      "   TCGA_Class: 38 (0.19%)\n",
      "   Putative_Target: 219 (1.09%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Dataset Overview:\")\n",
    "print(f\"   Total samples: {len(df):,}\")\n",
    "print(f\"   Total features: {len(df.columns)}\")\n",
    "\n",
    "# Target variable statistics\n",
    "print(f\"\\nüéØ Target Variable ({target_col}) Statistics:\")\n",
    "print(df[target_col].describe())\n",
    "\n",
    "# Categorical feature counts\n",
    "print(f\"\\nüìã Categorical Features:\")\n",
    "if 'Drug_Name' in df.columns:\n",
    "    n_drugs = df['Drug_Name'].nunique()\n",
    "    print(f\"   Drugs: {n_drugs:,} unique\")\n",
    "    print(f\"   Top 10 drugs by frequency:\")\n",
    "    print(df['Drug_Name'].value_counts().head(10).to_string())\n",
    "\n",
    "if 'Cell_Line_Name' in df.columns:\n",
    "    n_cell_lines = df['Cell_Line_Name'].nunique()\n",
    "    print(f\"\\n   Cell Lines: {n_cell_lines:,} unique\")\n",
    "\n",
    "if 'TCGA_Class' in df.columns:\n",
    "    n_tcga = df['TCGA_Class'].nunique()\n",
    "    print(f\"   TCGA Classes: {n_tcga:,} unique\")\n",
    "    print(f\"   Top 10 TCGA classes:\")\n",
    "    print(df['TCGA_Class'].value_counts().head(10).to_string())\n",
    "\n",
    "# Missing values check\n",
    "print(f\"\\n‚ö†Ô∏è  Missing Values:\")\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0]\n",
    "if len(missing_summary) > 0:\n",
    "    for col, count in missing_summary.items():\n",
    "        print(f\"   {col}: {count:,} ({count/len(df)*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No missing values in key columns!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19868c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "üîç Checking and filling missing values in categorical features...\n",
      "   ‚úÖ No missing values in Drug_Name\n",
      "   ‚úÖ Filled 38 missing values in TCGA_Class\n",
      "   ‚úÖ No missing values in Pathway_Name\n",
      "   ‚úÖ Filled 219 missing values in Putative_Target\n",
      "\n",
      "‚úÖ All missing values filled in categorical features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüîç Checking and filling missing values in categorical features...\")\n",
    "\n",
    "categorical_cols_to_encode = []\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col == 'Cell_Line_Name':\n",
    "        continue\n",
    "    \n",
    "    categorical_cols_to_encode.append(col)\n",
    "    if df[col].isna().sum() > 0:\n",
    "        print(f\"   ‚úÖ Filled {df[col].isna().sum()} missing values in {col}\")\n",
    "        df[col] = df[col].fillna('UNKNOWN')\n",
    "    else:\n",
    "        print(f\"   ‚úÖ No missing values in {col}\")\n",
    "\n",
    "print(f\"\\n‚úÖ All missing values filled in categorical features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac416d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¢ Encoding categorical features using OneHotEncoder...\n",
      "   Why OneHotEncoder? Drug names, TCGA classes have NO order (nominal data)\n",
      "   ‚úÖ OneHot encoded 4 categorical columns\n",
      "      Created 719 binary features\n",
      "      Original categories:\n",
      "         Drug_Name: 378 categories\n",
      "         TCGA_Class: 32 categories\n",
      "         Pathway_Name: 24 categories\n",
      "         Putative_Target: 289 categories\n",
      "      Example features: ['Drug_Name_5-Fluorouracil', 'Drug_Name_965-D2', 'Drug_Name_993-D2', 'Drug_Name_A-443654', 'Drug_Name_A-770041']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüî¢ Encoding categorical features using OneHotEncoder...\")\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "if categorical_cols_to_encode:\n",
    "    df_categorical = df[categorical_cols_to_encode].copy()\n",
    "    \n",
    "    # One-hot encoding preserves the nominal nature of these features without imposing artificial order\n",
    "    ohe = OneHotEncoder(\n",
    "        sparse_output=False,\n",
    "        handle_unknown='ignore',\n",
    "        drop='first'\n",
    "    )\n",
    "    \n",
    "    X_categorical_ohe = ohe.fit_transform(df_categorical)\n",
    "    categorical_feature_names = ohe.get_feature_names_out(categorical_cols_to_encode)\n",
    "    \n",
    "    print(f\"   ‚úÖ OneHot encoded {len(categorical_cols_to_encode)} categorical columns\")\n",
    "    print(f\"      Created {X_categorical_ohe.shape[1]} binary features\")\n",
    "    print(f\"      Original categories:\")\n",
    "    for col in categorical_cols_to_encode:\n",
    "        n_cats = df[col].nunique()\n",
    "        print(f\"         {col}: {n_cats} categories\")\n",
    "    print(f\"      Example features: {list(categorical_feature_names[:5])}\")\n",
    "    \n",
    "    ohe_encoder = ohe\n",
    "else:\n",
    "    X_categorical_ohe = np.array([]).reshape(len(df), 0)\n",
    "    categorical_feature_names = []\n",
    "    ohe_encoder = None\n",
    "    print(\"   ‚ö†Ô∏è  No categorical columns to encode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d4e7f552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 719)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_categorical_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6fdb7346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "719"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categorical_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2714bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¢ Handling high cardinality features...\n",
      "   ‚ö†Ô∏è  Cell_Line_Name: 958 categories (high cardinality)\n",
      "      Using LabelEncoder to avoid creating 958 binary features\n",
      "      Note: This loses nominal property, but keeps feature count manageable\n",
      "      ‚úÖ Encoded as 1 feature (values: 0 to 957)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüî¢ Handling high cardinality features...\")\n",
    "\n",
    "if 'Cell_Line_Name' in df.columns:\n",
    "    n_cell_lines = df['Cell_Line_Name'].nunique()\n",
    "    \n",
    "    if n_cell_lines > 50:\n",
    "        print(f\"   ‚ö†Ô∏è  Cell_Line_Name: {n_cell_lines} categories (high cardinality)\")\n",
    "        print(f\"      Using LabelEncoder to avoid creating {n_cell_lines} binary features\")\n",
    "        print(f\"      Note: This loses nominal property, but keeps feature count manageable\")\n",
    "        \n",
    "        # Practical trade-off: one feature instead of hundreds, though we lose the nominal property\n",
    "        le_cell = LabelEncoder()\n",
    "        cell_line_encoded = le_cell.fit_transform(df['Cell_Line_Name'])\n",
    "        X_cell_line = cell_line_encoded.reshape(-1, 1)\n",
    "        cell_line_feature_names = ['Cell_Line_Encoded']\n",
    "        cell_line_handled = True\n",
    "        \n",
    "        print(f\"      ‚úÖ Encoded as 1 feature (values: 0 to {n_cell_lines-1})\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Cell_Line_Name: {n_cell_lines} categories (low cardinality)\")\n",
    "        print(f\"      Using OneHotEncoder (correct for nominal data)\")\n",
    "        \n",
    "        ohe_cell = OneHotEncoder(\n",
    "            sparse_output=False,\n",
    "            handle_unknown='ignore',\n",
    "            drop='first'\n",
    "        )\n",
    "        X_cell_line = ohe_cell.fit_transform(df[['Cell_Line_Name']])\n",
    "        cell_line_feature_names = ohe_cell.get_feature_names_out(['Cell_Line_Name'])\n",
    "        cell_line_handled = True\n",
    "        \n",
    "        print(f\"      ‚úÖ Created {X_cell_line.shape[1]} binary features\")\n",
    "else:\n",
    "    X_cell_line = np.array([]).reshape(len(df), 0)\n",
    "    cell_line_feature_names = []\n",
    "    cell_line_handled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d82e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(categorical_feature_names) + list(cell_line_feature_names)\n",
    "X = np.concatenate([X_categorical_ohe, X_cell_line], axis=1)\n",
    "X = pd.DataFrame(X, columns=feature_names)\n",
    "X = pd.concat([X, df[['LN_IC50']]], axis=1)\n",
    "y = df['AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "66d1fb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug_Name_5-Fluorouracil</th>\n",
       "      <th>Drug_Name_965-D2</th>\n",
       "      <th>Drug_Name_993-D2</th>\n",
       "      <th>Drug_Name_A-443654</th>\n",
       "      <th>Drug_Name_A-770041</th>\n",
       "      <th>Drug_Name_A-83-01</th>\n",
       "      <th>Drug_Name_ACY-1215</th>\n",
       "      <th>Drug_Name_AGI-6780</th>\n",
       "      <th>Drug_Name_AICA Ribonucleotide</th>\n",
       "      <th>Drug_Name_AKT inhibitor VIII</th>\n",
       "      <th>...</th>\n",
       "      <th>Putative_Target_mTOR</th>\n",
       "      <th>Putative_Target_mTOR, LCK</th>\n",
       "      <th>Putative_Target_mTOR, PI3K</th>\n",
       "      <th>Putative_Target_mTORC1, mTORC2</th>\n",
       "      <th>Putative_Target_not defined</th>\n",
       "      <th>Putative_Target_p38</th>\n",
       "      <th>Putative_Target_p38, JNK2</th>\n",
       "      <th>Putative_Target_p38alpha, p38beta</th>\n",
       "      <th>Cell_Line_Encoded</th>\n",
       "      <th>LN_IC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>4.978434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0.961609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>4.434201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>2.278400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>1.726612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.026394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>3.942135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>3.818997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.013664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.085055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows √ó 721 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Drug_Name_5-Fluorouracil  Drug_Name_965-D2  Drug_Name_993-D2  \\\n",
       "0                           0.0               0.0               0.0   \n",
       "1                           0.0               0.0               0.0   \n",
       "2                           0.0               0.0               0.0   \n",
       "3                           0.0               0.0               0.0   \n",
       "4                           0.0               0.0               0.0   \n",
       "...                         ...               ...               ...   \n",
       "19995                       0.0               0.0               0.0   \n",
       "19996                       0.0               0.0               0.0   \n",
       "19997                       0.0               0.0               0.0   \n",
       "19998                       0.0               0.0               0.0   \n",
       "19999                       0.0               0.0               0.0   \n",
       "\n",
       "       Drug_Name_A-443654  Drug_Name_A-770041  Drug_Name_A-83-01  \\\n",
       "0                     0.0                 0.0                0.0   \n",
       "1                     0.0                 0.0                0.0   \n",
       "2                     0.0                 0.0                0.0   \n",
       "3                     0.0                 0.0                0.0   \n",
       "4                     0.0                 0.0                0.0   \n",
       "...                   ...                 ...                ...   \n",
       "19995                 0.0                 0.0                0.0   \n",
       "19996                 0.0                 0.0                0.0   \n",
       "19997                 0.0                 0.0                0.0   \n",
       "19998                 0.0                 0.0                0.0   \n",
       "19999                 0.0                 0.0                0.0   \n",
       "\n",
       "       Drug_Name_ACY-1215  Drug_Name_AGI-6780  Drug_Name_AICA Ribonucleotide  \\\n",
       "0                     0.0                 0.0                            0.0   \n",
       "1                     0.0                 0.0                            0.0   \n",
       "2                     0.0                 0.0                            0.0   \n",
       "3                     0.0                 0.0                            0.0   \n",
       "4                     0.0                 0.0                            0.0   \n",
       "...                   ...                 ...                            ...   \n",
       "19995                 0.0                 0.0                            0.0   \n",
       "19996                 0.0                 0.0                            0.0   \n",
       "19997                 0.0                 0.0                            0.0   \n",
       "19998                 0.0                 0.0                            0.0   \n",
       "19999                 0.0                 0.0                            0.0   \n",
       "\n",
       "       Drug_Name_AKT inhibitor VIII  ...  Putative_Target_mTOR  \\\n",
       "0                               0.0  ...                   0.0   \n",
       "1                               0.0  ...                   0.0   \n",
       "2                               0.0  ...                   0.0   \n",
       "3                               0.0  ...                   0.0   \n",
       "4                               0.0  ...                   0.0   \n",
       "...                             ...  ...                   ...   \n",
       "19995                           0.0  ...                   0.0   \n",
       "19996                           0.0  ...                   0.0   \n",
       "19997                           0.0  ...                   0.0   \n",
       "19998                           0.0  ...                   0.0   \n",
       "19999                           0.0  ...                   0.0   \n",
       "\n",
       "       Putative_Target_mTOR, LCK  Putative_Target_mTOR, PI3K  \\\n",
       "0                            0.0                         0.0   \n",
       "1                            0.0                         0.0   \n",
       "2                            0.0                         0.0   \n",
       "3                            0.0                         0.0   \n",
       "4                            0.0                         0.0   \n",
       "...                          ...                         ...   \n",
       "19995                        0.0                         0.0   \n",
       "19996                        0.0                         0.0   \n",
       "19997                        0.0                         0.0   \n",
       "19998                        0.0                         0.0   \n",
       "19999                        0.0                         0.0   \n",
       "\n",
       "       Putative_Target_mTORC1, mTORC2  Putative_Target_not defined  \\\n",
       "0                                 0.0                          0.0   \n",
       "1                                 0.0                          0.0   \n",
       "2                                 0.0                          0.0   \n",
       "3                                 0.0                          0.0   \n",
       "4                                 0.0                          0.0   \n",
       "...                               ...                          ...   \n",
       "19995                             0.0                          0.0   \n",
       "19996                             0.0                          0.0   \n",
       "19997                             0.0                          0.0   \n",
       "19998                             0.0                          0.0   \n",
       "19999                             0.0                          0.0   \n",
       "\n",
       "       Putative_Target_p38  Putative_Target_p38, JNK2  \\\n",
       "0                      0.0                        0.0   \n",
       "1                      0.0                        0.0   \n",
       "2                      0.0                        0.0   \n",
       "3                      0.0                        0.0   \n",
       "4                      0.0                        0.0   \n",
       "...                    ...                        ...   \n",
       "19995                  0.0                        0.0   \n",
       "19996                  0.0                        0.0   \n",
       "19997                  0.0                        0.0   \n",
       "19998                  0.0                        0.0   \n",
       "19999                  0.0                        0.0   \n",
       "\n",
       "       Putative_Target_p38alpha, p38beta  Cell_Line_Encoded   LN_IC50  \n",
       "0                                    0.0              684.0  4.978434  \n",
       "1                                    0.0              308.0  0.961609  \n",
       "2                                    0.0              523.0  4.434201  \n",
       "3                                    0.0              641.0  2.278400  \n",
       "4                                    0.0              846.0  1.726612  \n",
       "...                                  ...                ...       ...  \n",
       "19995                                0.0              120.0  2.026394  \n",
       "19996                                0.0              529.0  3.942135  \n",
       "19997                                0.0              752.0  3.818997  \n",
       "19998                                0.0              219.0  5.013664  \n",
       "19999                                0.0              319.0  1.085055  \n",
       "\n",
       "[20000 rows x 721 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " DATA VISUALIZATION\n",
      "======================================================================\n",
      "\n",
      "üìä Creating visualizations...\n",
      "   ‚úÖ Saved: outputs/target_distribution.png\n",
      "   ‚úÖ Saved: outputs/drug_distribution.png\n",
      "   ‚úÖ Saved: outputs/tcga_distribution.png\n",
      "\n",
      "‚úÖ All visualizations saved to outputs/ directory\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" DATA VISUALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create output directory for plots\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "# Create summary DataFrame for visualization\n",
    "df_summary = X.copy()\n",
    "df_summary[target_col] = y.copy()\n",
    "if 'Drug_Name' in df.columns:\n",
    "    df_summary['Drug_Name'] = df['Drug_Name'].values\n",
    "if 'Cell_Line_Name' in df.columns:\n",
    "    df_summary['Cell_Line_Name'] = df['Cell_Line_Name'].values\n",
    "\n",
    "print(\"\\nüìä Creating visualizations...\")\n",
    "\n",
    "# 1. Target variable distribution\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "df_summary[target_col].hist(bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel(target_col)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Distribution of {target_col}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "df_summary[target_col].plot(kind='box', vert=True)\n",
    "plt.ylabel(target_col)\n",
    "plt.title(f'Box Plot of {target_col}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Q-Q plot for normality check\n",
    "from scipy import stats\n",
    "stats.probplot(df_summary[target_col], dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot (Normality Check)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/target_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"   ‚úÖ Saved: outputs/target_distribution.png\")\n",
    "\n",
    "# 2. Drug distribution\n",
    "if 'Drug_Name' in df_summary.columns:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    drug_counts = df_summary['Drug_Name'].value_counts().head(20)  # Top 20\n",
    "    plt.barh(range(len(drug_counts)), drug_counts.values)\n",
    "    plt.yticks(range(len(drug_counts)), drug_counts.index)\n",
    "    plt.xlabel('Number of Samples')\n",
    "    plt.ylabel('Drug Name')\n",
    "    plt.title('Top 20 Drugs by Sample Count')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/drug_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"   ‚úÖ Saved: outputs/drug_distribution.png\")\n",
    "\n",
    "# 3. TCGA class distribution\n",
    "if 'TCGA_Class' in df.columns:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    tcga_counts = df['TCGA_Class'].value_counts().head(15)  # Top 15\n",
    "    plt.barh(range(len(tcga_counts)), tcga_counts.values)\n",
    "    plt.yticks(range(len(tcga_counts)), tcga_counts.index)\n",
    "    plt.xlabel('Number of Samples')\n",
    "    plt.ylabel('TCGA Class')\n",
    "    plt.title('Top 15 TCGA Classes by Sample Count')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/tcga_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"   ‚úÖ Saved: outputs/tcga_distribution.png\")\n",
    "\n",
    "# 4. Target by drug (if not too many drugs)\n",
    "if 'Drug_Name' in df_summary.columns and df_summary['Drug_Name'].nunique() <= 20:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    df_summary.boxplot(column=target_col, by='Drug_Name', ax=plt.gca())\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title(f'{target_col} Distribution by Drug')\n",
    "    plt.suptitle('')  # Remove default title\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/target_by_drug.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"   ‚úÖ Saved: outputs/target_by_drug.png\")\n",
    "\n",
    "print(\"\\n‚úÖ All visualizations saved to outputs/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55298fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3: DATA PREPROCESSING\n",
      "======================================================================\n",
      "\n",
      "üìä Splitting data into train/test sets...\n",
      "   ‚úÖ Training set: 16,000 samples (80.0%)\n",
      "   ‚úÖ Test set: 4,000 samples (20.0%)\n",
      "   ‚úÖ Features: 721\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 3: DATA PREPROCESSING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìä Splitting data into train/test sets...\")\n",
    "# Splitting first prevents data leakage - all preprocessing will be fitted only on training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"   ‚úÖ Training set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Test set: {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"   ‚úÖ Features: {X_train.shape[1]}\")\n",
    "\n",
    "X_test_original = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8b245410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 721)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2571e1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drug_Name_5-Fluorouracil    float64\n",
       "Drug_Name_965-D2            float64\n",
       "Drug_Name_993-D2            float64\n",
       "Drug_Name_A-443654          float64\n",
       "Drug_Name_A-770041          float64\n",
       "                             ...   \n",
       "Cell_Line_Encoded           float64\n",
       "LN_IC50                     float64\n",
       "AUC                         float64\n",
       "Drug_Name                    object\n",
       "Cell_Line_Name               object\n",
       "Length: 724, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982691e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Feature selection...\n",
      "   Selecting top 500 features from 721 total\n",
      "   ‚úÖ Selected 500 features\n",
      "      Reduction: 30.7%\n",
      "\n",
      "   Top 10 selected features:\n",
      "      LN_IC50: 0.76\n",
      "      Cell_Line_Encoded: 0.15\n",
      "      Pathway_Name_Chromatin histone acetylation: 0.01\n",
      "      Pathway_Name_Mitosis: 0.01\n",
      "      TCGA_Class_DLBC: 0.01\n",
      "      Pathway_Name_PI3K/MTOR signaling: 0.01\n",
      "      TCGA_Class_ALL: 0.01\n",
      "      Pathway_Name_DNA replication: 0.01\n",
      "      Pathway_Name_Hormone-related: 0.01\n",
      "      Pathway_Name_WNT signaling: 0.01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\nüéØ Feature selection...\")\n",
    "\n",
    "if X_train.shape[0] > 15000:\n",
    "    n_features_to_select = min(500, X_train.shape[1])\n",
    "else:\n",
    "    n_features_to_select = min(150, X_train.shape[1])\n",
    "\n",
    "print(f\"   Selecting top {n_features_to_select} features from {X_train.shape[1]} total\")\n",
    "\n",
    "# Mutual information captures both linear and non-linear relationships, making it more flexible than correlation-based methods\n",
    "selector = SelectKBest(score_func=mutual_info_regression, k=n_features_to_select)\n",
    "\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    all_feature_names = list(X_train.columns)\n",
    "else:\n",
    "    all_feature_names = feature_names if len(feature_names) == X_train.shape[1] else list(range(X_train.shape[1]))\n",
    "selected_feature_names = [all_feature_names[i] for i in selected_feature_indices]\n",
    "\n",
    "print(f\"   ‚úÖ Selected {X_train_selected.shape[1]} features\")\n",
    "print(f\"      Reduction: {(1 - X_train_selected.shape[1]/X_train.shape[1])*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n   Top 10 selected features:\")\n",
    "feature_scores = selector.scores_[selected_feature_indices]\n",
    "top_features = sorted(zip(selected_feature_names, feature_scores), \n",
    "                      key=lambda x: x[1], reverse=True)[:10]\n",
    "for feat_name, score in top_features:\n",
    "    print(f\"      {feat_name}: {score:.2f}\")\n",
    "\n",
    "X_train = X_train_selected\n",
    "X_test = X_test_selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "81e31b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìè Scaling features...\n",
      "   ‚úÖ Features scaled using RobustScaler (fitted on train only)\n",
      "      Train range: [-3.46, 2.81]\n",
      "      Test range: [-3.51, 2.61]\n",
      "\n",
      "‚úÖ Data preprocessing complete (no data leakage!)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìè Scaling features...\")\n",
    "\n",
    "# RobustScaler is more resistant to outliers than StandardScaler, which matters for real-world biological data\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"   ‚úÖ Features scaled using RobustScaler (fitted on train only)\")\n",
    "print(f\"      Train range: [{X_train_scaled.min():.2f}, {X_train_scaled.max():.2f}]\")\n",
    "print(f\"      Test range: [{X_test_scaled.min():.2f}, {X_test_scaled.max():.2f}]\")\n",
    "\n",
    "print(\"\\n‚úÖ Data preprocessing complete (no data leakage!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6c9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 4: MODEL TRAINING AND COMPARISON\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" MODEL TRAINING AND COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "models = {}\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e23333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "MODEL 1: LINEAR REGRESSION (Baseline)\n",
      "----------------------------------------------------------------------\n",
      "   Training Linear Regression...\n",
      "   ‚úÖ Training complete!\n",
      "   üìä Results:\n",
      "      RMSE: 0.0764 (lower is better)\n",
      "      MAE:  0.0530 (lower is better)\n",
      "      R¬≤:   0.8197 (higher is better, max=1.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"MODEL 1: LINEAR REGRESSION (Baseline)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "print(\"   Training Linear Regression...\")\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "models['Linear Regression'] = lr_model\n",
    "results['Linear Regression'] = {\n",
    "    'RMSE': rmse_lr,\n",
    "    'MAE': mae_lr,\n",
    "    'R2': r2_lr,\n",
    "    'predictions': y_pred_lr\n",
    "}\n",
    "\n",
    "print(f\"   ‚úÖ Training complete!\")\n",
    "print(f\"   üìä Results:\")\n",
    "print(f\"      RMSE: {rmse_lr:.4f} (lower is better)\")\n",
    "print(f\"      MAE:  {mae_lr:.4f} (lower is better)\")\n",
    "print(f\"      R¬≤:   {r2_lr:.4f} (higher is better, max=1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1296d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "MODEL 2: RANDOM FOREST REGRESSION\n",
      "----------------------------------------------------------------------\n",
      "   Training Random Forest (this may take a few minutes)...\n",
      "   ‚úÖ Training complete!\n",
      "   üìä Results:\n",
      "      RMSE: 0.0807\n",
      "      MAE:  0.0533\n",
      "      R¬≤:   0.7988\n",
      "\n",
      "   üîç Feature Importance Analysis:\n",
      "   Top 10 Most Important Features:\n",
      "      LN_IC50                       : 0.7849\n",
      "      Pathway_Name_Mitosis          : 0.0153\n",
      "      Putative_Target_HSF1          : 0.0144\n",
      "      Drug_Name_Bryostatin 1        : 0.0087\n",
      "      Putative_Target_PKC           : 0.0079\n",
      "      Drug_Name_DMOG                : 0.0077\n",
      "      Putative_Target_PI3K (class 1), MTORC1, MTORC2: 0.0072\n",
      "      Putative_Target_dsDNA break induction: 0.0067\n",
      "      Putative_Target_HIF-PH        : 0.0064\n",
      "      Cell_Line_Encoded             : 0.0061\n",
      "   ‚úÖ Saved: outputs/feature_importance.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"MODEL 2: RANDOM FOREST REGRESSION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"   Training Random Forest (this may take a few minutes)...\")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "models['Random Forest'] = rf_model\n",
    "results['Random Forest'] = {\n",
    "    'RMSE': rmse_rf,\n",
    "    'MAE': mae_rf,\n",
    "    'R2': r2_rf,\n",
    "    'predictions': y_pred_rf\n",
    "}\n",
    "\n",
    "print(f\"   ‚úÖ Training complete!\")\n",
    "print(f\"   üìä Results:\")\n",
    "print(f\"      RMSE: {rmse_rf:.4f}\")\n",
    "print(f\"      MAE:  {mae_rf:.4f}\")\n",
    "print(f\"      R¬≤:   {r2_rf:.4f}\")\n",
    "\n",
    "print(f\"\\n   üîç Feature Importance Analysis:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': selected_feature_names,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"   Top 10 Most Important Features:\")\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"      {row['Feature']:30s}: {row['Importance']:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_20 = feature_importance.head(20)\n",
    "plt.barh(range(len(top_20)), top_20['Importance'].values)\n",
    "plt.yticks(range(len(top_20)), top_20['Feature'].values)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 20 Most Important Features (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ‚úÖ Saved: outputs/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5767cab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "MODEL 3: XGBOOST REGRESSION\n",
      "----------------------------------------------------------------------\n",
      "   Training XGBoost (this may take a few minutes)...\n",
      "   ‚úÖ Training complete!\n",
      "   üìä Results:\n",
      "      RMSE: 0.0700\n",
      "      MAE:  0.0465\n",
      "      R¬≤:   0.8487\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"MODEL 3: XGBOOST REGRESSION\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "print(\"   Training XGBoost (this may take a few minutes)...\")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "models['XGBoost'] = xgb_model\n",
    "results['XGBoost'] = {\n",
    "    'RMSE': rmse_xgb,\n",
    "    'MAE': mae_xgb,\n",
    "    'R2': r2_xgb,\n",
    "    'predictions': y_pred_xgb\n",
    "}\n",
    "\n",
    "print(f\"   ‚úÖ Training complete!\")\n",
    "print(f\"   üìä Results:\")\n",
    "print(f\"      RMSE: {rmse_xgb:.4f}\")\n",
    "print(f\"      MAE:  {mae_xgb:.4f}\")\n",
    "print(f\"      R¬≤:   {r2_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32960bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 5: MODEL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "üìä Model Performance Comparison:\n",
      "            Model     RMSE      MAE       R2\n",
      "          XGBoost 0.070001 0.046535 0.848689\n",
      "Linear Regression 0.076421 0.053047 0.819662\n",
      "    Random Forest 0.080725 0.053271 0.798778\n",
      "\n",
      "‚úÖ Saved: outputs/regression_model_comparison.png\n",
      "\n",
      "üèÜ Best Model: XGBoost\n",
      "   R¬≤ Score: 0.8487\n",
      "   RMSE: 0.0700\n",
      "   MAE: 0.0465\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 5: MODEL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'RMSE': [results[m]['RMSE'] for m in results.keys()],\n",
    "    'MAE': [results[m]['MAE'] for m in results.keys()],\n",
    "    'R2': [results[m]['R2'] for m in results.keys()]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Model Performance Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'R2']\n",
    "for i, metric in enumerate(metrics):\n",
    "    axes[i].barh(comparison_df['Model'], comparison_df[metric], color=['#2ecc71', '#3498db', '#e74c3c'])\n",
    "    axes[i].set_xlabel(metric, fontsize=12)\n",
    "    axes[i].set_title(f'Model Comparison - {metric}', fontsize=14, fontweight='bold')\n",
    "    axes[i].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add value labels\n",
    "    for j, v in enumerate(comparison_df[metric]):\n",
    "        axes[i].text(v, j, f' {v:.4f}', va='center', fontsize=10)\n",
    "    \n",
    "    if metric == 'R2':\n",
    "        axes[i].set_xlim([0, max(1.0, comparison_df[metric].max() * 1.1)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/regression_model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"\\n‚úÖ Saved: outputs/regression_model_comparison.png\")\n",
    "\n",
    "# Select best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "best_r2 = comparison_df.iloc[0]['R2']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   R¬≤ Score: {best_r2:.4f}\")\n",
    "print(f\"   RMSE: {comparison_df.iloc[0]['RMSE']:.4f}\")\n",
    "print(f\"   MAE: {comparison_df.iloc[0]['MAE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e97edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 6: HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "Tuning hyperparameters for: XGBoost\n",
      "Original R¬≤: 0.8487\n",
      "\n",
      "   üîç Performing Grid Search with 5-fold cross-validation...\n",
      "   This may take 10-30 minutes depending on dataset size...\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "\n",
      "   ‚úÖ Grid Search Complete!\n",
      "   Best Parameters: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300, 'subsample': 0.9}\n",
      "   Best CV R¬≤ Score: 0.8978\n",
      "\n",
      "   üìä Comparison:\n",
      "      Original R¬≤: 0.8487\n",
      "      Tuned R¬≤:    0.9027\n",
      "      Improvement: +0.0540 (+6.36%)\n",
      "   ‚úÖ Tuned model is better! Using tuned model.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 6: HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"Tuning hyperparameters for: {best_model_name}\")\n",
    "print(f\"Original R¬≤: {best_r2:.4f}\")\n",
    "\n",
    "if best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 15, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    base_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "    \n",
    "elif best_model_name == 'XGBoost':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [6, 8, 10],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    base_model = xgb.XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)\n",
    "    \n",
    "elif best_model_name == 'Linear Regression':\n",
    "    print(\"   ‚ö†Ô∏è  Linear Regression has limited hyperparameters to tune\")\n",
    "    print(\"   Skipping hyperparameter tuning for Linear Regression\")\n",
    "    tuned_model = best_model\n",
    "    param_grid = None\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Hyperparameter tuning not implemented for {best_model_name}\")\n",
    "    tuned_model = best_model\n",
    "    param_grid = None\n",
    "\n",
    "if param_grid is not None:\n",
    "    print(f\"\\n   üîç Performing Grid Search with 5-fold cross-validation...\")\n",
    "    print(f\"   This may take 10-30 minutes depending on dataset size...\")\n",
    "    \n",
    "    if X_train.shape[0] > 50000:\n",
    "        print(\"   ‚ö†Ô∏è  Large dataset detected. Using reduced parameter grid for speed...\")\n",
    "        if best_model_name == 'Random Forest':\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [10, 15],\n",
    "                'min_samples_split': [5, 10]\n",
    "            }\n",
    "        elif best_model_name == 'XGBoost':\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [6, 8],\n",
    "                'learning_rate': [0.05, 0.1]\n",
    "            }\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        base_model,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    tuned_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_cv_score = grid_search.best_score_\n",
    "    \n",
    "    print(f\"\\n   ‚úÖ Grid Search Complete!\")\n",
    "    print(f\"   Best Parameters: {best_params}\")\n",
    "    print(f\"   Best CV R¬≤ Score: {best_cv_score:.4f}\")\n",
    "    \n",
    "    y_pred_tuned = tuned_model.predict(X_test_scaled)\n",
    "    r2_tuned = r2_score(y_test, y_pred_tuned)\n",
    "    rmse_tuned = np.sqrt(mean_squared_error(y_test, y_pred_tuned))\n",
    "    mae_tuned = mean_absolute_error(y_test, y_pred_tuned)\n",
    "    \n",
    "    improvement = r2_tuned - best_r2\n",
    "    \n",
    "    print(f\"\\n   üìä Comparison:\")\n",
    "    print(f\"      Original R¬≤: {best_r2:.4f}\")\n",
    "    print(f\"      Tuned R¬≤:    {r2_tuned:.4f}\")\n",
    "    print(f\"      Improvement: {improvement:+.4f} ({improvement/best_r2*100:+.2f}%)\")\n",
    "    \n",
    "    if improvement > 0:\n",
    "        print(f\"   ‚úÖ Tuned model is better! Using tuned model.\")\n",
    "        best_model = tuned_model\n",
    "        models[best_model_name] = tuned_model\n",
    "        results[best_model_name]['R2'] = r2_tuned\n",
    "        results[best_model_name]['RMSE'] = rmse_tuned\n",
    "        results[best_model_name]['MAE'] = mae_tuned\n",
    "        results[best_model_name]['predictions'] = y_pred_tuned\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Tuned model didn't improve. Using original model.\")\n",
    "        best_model = models[best_model_name]\n",
    "else:\n",
    "    best_model = models[best_model_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a43c007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 7: PREDICTION VISUALIZATION\n",
      "======================================================================\n",
      "‚úÖ Saved: outputs/predictions_vs_actual.png\n",
      "‚úÖ Saved: outputs/error_distribution.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 7: PREDICTION VISUALIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "y_pred_best = best_model.predict(X_test_scaled)\n",
    "\n",
    "# 1. Predictions vs Actual scatter plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.5, s=20)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel(f'Actual {target_col}', fontsize=12)\n",
    "plt.ylabel(f'Predicted {target_col}', fontsize=12)\n",
    "plt.title(f'Predictions vs Actual - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate and display R¬≤ on plot\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "plt.text(0.05, 0.95, f'R¬≤ = {r2_best:.4f}', transform=plt.gca().transAxes,\n",
    "         fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# 2. Residual plot\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test - y_pred_best\n",
    "plt.scatter(y_pred_best, residuals, alpha=0.5, s=20)\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel(f'Predicted {target_col}', fontsize=12)\n",
    "plt.ylabel('Residuals (Actual - Predicted)', fontsize=12)\n",
    "plt.title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/predictions_vs_actual.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"‚úÖ Saved: outputs/predictions_vs_actual.png\")\n",
    "\n",
    "# 3. Error distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Residuals (Actual - Predicted)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Prediction Errors', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='r', linestyle='--', lw=2, label='Zero Error')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/error_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"‚úÖ Saved: outputs/error_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a36a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 8: SAVE MODEL\n",
      "======================================================================\n",
      "‚úÖ Model saved to: models/xgboost_regression.pkl\n",
      "‚úÖ Scaler saved to: models/regression_scaler.pkl\n",
      "‚úÖ Feature selector saved to: models/regression_selector.pkl\n",
      "‚úÖ OneHotEncoder saved to: models/regression_onehot_encoder.pkl\n",
      "‚úÖ Cell line encoder (LabelEncoder) saved to: models/regression_cell_line_encoder.pkl\n",
      "‚úÖ Feature info saved to: models/feature_info.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STEP 8: SAVE MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model and preprocessing components\n",
    "model_filename = best_model_name.lower().replace(\" \", \"_\")\n",
    "model_path = f'models/{model_filename}_regression.pkl'\n",
    "scaler_path = 'models/regression_scaler.pkl'\n",
    "selector_path = 'models/regression_selector.pkl'\n",
    "\n",
    "joblib.dump(best_model, model_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "joblib.dump(selector, selector_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n",
    "print(f\"‚úÖ Scaler saved to: {scaler_path}\")\n",
    "print(f\"‚úÖ Feature selector saved to: {selector_path}\")\n",
    "\n",
    "# Save OneHotEncoder (for categorical features)\n",
    "if ohe_encoder is not None:\n",
    "    ohe_path = 'models/regression_onehot_encoder.pkl'\n",
    "    joblib.dump(ohe_encoder, ohe_path)\n",
    "    print(f\"‚úÖ OneHotEncoder saved to: {ohe_path}\")\n",
    "\n",
    "# Save cell line encoder (if used)\n",
    "if cell_line_handled and 'Cell_Line_Name' in df.columns:\n",
    "    if n_cell_lines > 50:  # Was using LabelEncoder\n",
    "        cell_encoder_path = 'models/regression_cell_line_encoder.pkl'\n",
    "        joblib.dump(le_cell, cell_encoder_path)\n",
    "        print(f\"‚úÖ Cell line encoder (LabelEncoder) saved to: {cell_encoder_path}\")\n",
    "\n",
    "# Save feature names for reference\n",
    "import json\n",
    "feature_info = {\n",
    "    'selected_features': selected_feature_names,\n",
    "    'target_column': target_col,\n",
    "    'model_type': best_model_name,\n",
    "    'categorical_columns': categorical_cols_to_encode if categorical_cols_to_encode else [],\n",
    "    'encoding_method': 'OneHotEncoder' if ohe_encoder is not None else 'None'\n",
    "}\n",
    "with open('models/feature_info.json', 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2)\n",
    "print(f\"‚úÖ Feature info saved to: models/feature_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ede951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Inference function created!\n",
      "   Use predict_drug_response() to make predictions on new data\n",
      "\n",
      "üß™ Testing inference function...\n",
      "   Test prediction: 0.9158\n",
      "   Actual value: 0.9222\n",
      "   Error: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SelectKBest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def predict_drug_response(gene_expression_data, categorical_features=None,\n",
    "                          model_path=model_path, scaler_path=scaler_path,\n",
    "                          selector_path=selector_path):\n",
    "    \"\"\"\n",
    "    Predict drug response from gene expression and categorical features\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gene_expression_data : np.array or list\n",
    "        Gene expression values (n_samples, n_genes)\n",
    "        Should match the number of genes used in training\n",
    "    categorical_features : dict, optional\n",
    "        Dictionary with keys: 'TCGA_Class', 'Drug_Name', etc.\n",
    "        Values should be the actual category names (will be encoded)\n",
    "    model_path : str\n",
    "        Path to saved model\n",
    "    scaler_path : str\n",
    "        Path to saved scaler\n",
    "    selector_path : str\n",
    "        Path to saved feature selector\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : np.array\n",
    "        Predicted drug response values\n",
    "    \"\"\"\n",
    "    # Load models\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    selector = joblib.load(selector_path)\n",
    "    \n",
    "    # Load OneHotEncoder if available\n",
    "    ohe_path = 'models/regression_onehot_encoder.pkl'\n",
    "    ohe = None\n",
    "    if os.path.exists(ohe_path):\n",
    "        ohe = joblib.load(ohe_path)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    if isinstance(gene_expression_data, list):\n",
    "        gene_expression_data = np.array(gene_expression_data)\n",
    "    \n",
    "    # Reshape if single sample\n",
    "    if gene_expression_data.ndim == 1:\n",
    "        gene_expression_data = gene_expression_data.reshape(1, -1)\n",
    "    \n",
    "    # Handle categorical features using OneHotEncoder\n",
    "    X_categorical_encoded = None\n",
    "    if categorical_features and ohe is not None:\n",
    "        # Prepare categorical data\n",
    "        categorical_data = []\n",
    "        categorical_cols = []\n",
    "        for col in ohe.feature_names_in_ if hasattr(ohe, 'feature_names_in_') else []:\n",
    "            if col in categorical_features:\n",
    "                categorical_data.append([categorical_features[col]])\n",
    "                categorical_cols.append(col)\n",
    "        \n",
    "        if categorical_data:\n",
    "            # Fill missing values\n",
    "            categorical_df = pd.DataFrame(categorical_data, columns=categorical_cols)\n",
    "            categorical_df = categorical_df.fillna('UNKNOWN')\n",
    "            \n",
    "            # OneHot encode\n",
    "            X_categorical_encoded = ohe.transform(categorical_df)\n",
    "    \n",
    "    # Combine gene expression and categorical features\n",
    "    if X_categorical_encoded is not None:\n",
    "        X_combined = np.hstack([gene_expression_data, X_categorical_encoded])\n",
    "    else:\n",
    "        X_combined = gene_expression_data\n",
    "        if categorical_features:\n",
    "            print(\"‚ö†Ô∏è  Warning: Categorical features provided but OneHotEncoder not found\")\n",
    "            print(\"   Using only gene expression features\")\n",
    "    \n",
    "    # Feature selection\n",
    "    X_selected = selector.transform(X_combined)\n",
    "    \n",
    "    # Scale\n",
    "    X_scaled = scaler.transform(X_selected)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(X_scaled)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "print(\"\\n‚úÖ Inference function created!\")\n",
    "print(\"   Use predict_drug_response() to make predictions on new data\")\n",
    "\n",
    "# Test inference function\n",
    "print(\"\\nüß™ Testing inference function...\")\n",
    "# Use first test sample (all features - categorical encoded + numeric features)\n",
    "# Note: The inference function expects gene_expression_data, but our data structure\n",
    "# has categorical features (one-hot encoded) + numeric features (LN_IC50)\n",
    "# So we pass all features as \"gene_expression_data\" for testing\n",
    "if isinstance(X_test_original, pd.DataFrame):\n",
    "    test_sample = X_test_original.iloc[:1].values\n",
    "else:\n",
    "    test_sample = X_test_original[:1, :]\n",
    "pred_test = predict_drug_response(test_sample)\n",
    "print(f\"   Test prediction: {pred_test[0]:.4f}\")\n",
    "# Handle both Series and array for y_test\n",
    "actual_value = y_test.iloc[0] if hasattr(y_test, 'iloc') else y_test[0]\n",
    "print(f\"   Actual value: {actual_value:.4f}\")\n",
    "print(f\"   Error: {abs(pred_test[0] - actual_value):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c369f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PROJECT 3 COMPLETE! üéâ\n",
      "======================================================================\n",
      "\n",
      "üìä Final Results:\n",
      "   Best Model: XGBoost\n",
      "   R¬≤ Score: 0.9027\n",
      "   RMSE: 0.0561\n",
      "   MAE: 0.0321\n",
      "\n",
      "üìÅ Outputs saved:\n",
      "   - Model: models/xgboost_regression.pkl\n",
      "   - Visualizations: outputs/ directory\n",
      "   - Feature importance: outputs/feature_importance.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PROJECT 3 COMPLETE! üéâ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Final Results:\")\n",
    "print(f\"   Best Model: {best_model_name}\")\n",
    "print(f\"   R¬≤ Score: {results[best_model_name]['R2']:.4f}\")\n",
    "print(f\"   RMSE: {results[best_model_name]['RMSE']:.4f}\")\n",
    "print(f\"   MAE: {results[best_model_name]['MAE']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Outputs saved:\")\n",
    "print(f\"   - Model: {model_path}\")\n",
    "print(f\"   - Visualizations: outputs/ directory\")\n",
    "print(f\"   - Feature importance: outputs/feature_importance.png\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
